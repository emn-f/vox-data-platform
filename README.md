# ğŸ² Vox Data Platform

O **Vox Data Platform** Ã© o mÃ³dulo responsÃ¡vel pela ingestÃ£o, processamento e indexaÃ§Ã£o de dados para a base de conhecimento do Vox AI. Ele atua como um pipeline ETL (Extract, Transform, Load) automatizado, convertendo documentos brutos em vetores semÃ¢nticos prontos para serem utilizados pelo sistema de RAG (Retrieval-Augmented Generation).

## ğŸš€ Funcionalidades

- **ExtraÃ§Ã£o de Texto**: Leitura automatizada de arquivos PDF armazenados localmente.
- **GeraÃ§Ã£o de Embeddings**: Utiliza o modelo `text-embedding-004` do Google Gemini para criar representaÃ§Ãµes vetoriais do conteÃºdo.
- **Armazenamento Vetorial**: IntegraÃ§Ã£o direta com o Supabase para armazenar os textos processados e seus respectivos vetores na tabela `knowledge_base_etl`.
- **OrganizaÃ§Ã£o AutomÃ¡tica**: Move arquivos processados com sucesso da pasta de entrada (`raw`) para a pasta de concluÃ­dos (`processed`), mantendo o diretÃ³rio limpo.

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.x**
- **Google GenAI SDK**: Para geraÃ§Ã£o de embeddings.
- **Supabase Client**: Para conexÃ£o e operaÃ§Ãµes no banco de dados.
- **PyPDF**: Para extraÃ§Ã£o de texto de PDFs.
- **Python-Dotenv**: Para gerenciamento de variÃ¡veis de ambiente.

## âš™ï¸ ConfiguraÃ§Ã£o

1. **Clone o repositÃ³rio** (caso ainda nÃ£o tenha feito).

2. **Crie um ambiente virtual** (recomendado):
   ```bash
   python -m venv venv
   # Windows
   .\venv\Scripts\activate
   # Linux/Mac
   source venv/bin/activate
   ```

3. **Instale as dependÃªncias**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure as VariÃ¡veis de Ambiente**:
   Crie um arquivo `.env` na raiz do projeto seguindo o exemplo abaixo:

   ```env
   SUPABASE_URL=sua_url_supabase
   SUPABASE_KEY=sua_chave_supabase
   GEMINI_API_KEY=sua_chave_api_google_gemini
   ```

5. **ConfiguraÃ§Ã£o do Banco de Dados (Supabase)**:
   
   VocÃª precisarÃ¡ criar uma tabela chamada `knowledge_base_etl` no seu projeto Supabase. Certifique-se de habilitar a extensÃ£o `vector` antes. execute o seguinte comando SQL no **SQL Editor** do Supabase:

   ```sql
   -- Habilita a extensÃ£o pgvector para trabalhar com embeddings
   create extension if not exists vector;

   -- Cria a tabela para armazenar os dados e vetores
   create table knowledge_base_etl (
     id bigint primary key generated always as identity,
     created_at timestamp with time zone default now(),
     topico text,
     descricao text,
     embedding vector(768), -- 768 dimensÃµes para o modelo text-embedding-004
     autor text
   );
   ```

## ğŸ“¦ Como Usar

1. **Adicione os arquivos**:
   Coloque os arquivos PDF que deseja processar na pasta:
   ```
   data/raw/
   ```
   *(Se a pasta nÃ£o existir, o script a criarÃ¡ automaticamente na primeira execuÃ§Ã£o)*

2. **Execute o pipeline de ingestÃ£o**:
   ```bash
   python scripts/etl_ingestao.py
   ```

3. **Verifique o resultado**:
   - Os arquivos processados com sucesso serÃ£o movidos para `data/processed/`.
   - Os dados e vetores estarÃ£o disponÃ­veis na tabela `knowledge_base_etl` do seu projeto Supabase.
   - Logs detalhados serÃ£o exibidos no terminal informando o status de cada arquivo.

## ğŸ“‚ Estrutura do Projeto

```
vox-data-platform/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/          # Local para colocar novos PDFs
â”‚   â””â”€â”€ processed/    # Arquivos jÃ¡ processados (movidos automaticamente)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ db_connect.py   # Gerencia conexÃµes com Supabase e Gemini
â”‚   â””â”€â”€ etl_ingestao.py # Script principal do pipeline ETL
â”œâ”€â”€ tests/            # Testes automatizados (pytest)
â”œâ”€â”€ .env              # VariÃ¡veis de ambiente (nÃ£o versionado)
â”œâ”€â”€ requirements.txt  # DependÃªncias do projeto
â””â”€â”€ README.md         # DocumentaÃ§Ã£o
```

## ğŸ§ª Testes

Para executar os testes automatizados:

```bash
pytest
```
